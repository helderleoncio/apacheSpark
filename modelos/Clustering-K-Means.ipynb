{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupando automóveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local[*]\") \\\n",
    "   .appName(\"Nome do Projeto\") \\\n",
    "   .config(\"spark.executor.memory\", \"6gb\") \\\n",
    "   .config('spark.sql.debug.maxToStringFields', 2000) \\\n",
    "   .config('spark.debug.maxToStringFields', 2000) \\\n",
    "   .config(\"spark.sql.caseSensitive\", \"false\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados e gerando um RDD\n",
    "carrosRDD = sc.textFile(\"carros2.csv\")\n",
    "carrosRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a primeira linha do arquivo (cabeçalho)\n",
    "primeiraLinha = carrosRDD.first()\n",
    "carrosRDD2 = carrosRDD.filter(lambda x: x != primeiraLinha)\n",
    "carrosRDD2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrosRDD2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo e limpando os dados\n",
    "def transformToNumeric( inputStr) :\n",
    "    attList = inputStr.split(\",\")\n",
    "\n",
    "    doors = 1.0 if attList[3] == \"two\" else 2.0\n",
    "    body = 1.0 if attList[4] == \"sedan\" else 2.0 \n",
    "       \n",
    "    linhas = Row(DOORS = doors, BODY = float(body), HP = float(attList[7]), RPM = float(attList[8]),\n",
    "                 MPG = float(attList[9]))\n",
    "    return linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função\n",
    "carrosRDD3 = carrosRDD2.map(transformToNumeric)\n",
    "carrosRDD3.persist()\n",
    "carrosRDD3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Dataframe\n",
    "carrosDF = spSession.createDataFrame(carrosRDD3)\n",
    "carrosDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumarizando os dados e extraindo a média e o desvio padrão\n",
    "estats = carrosDF.describe().toPandas()\n",
    "medias = estats.iloc[1,1:5].values.tolist()\n",
    "desvios = estats.iloc[2,1:5].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando a média e o desvio padrão e variáves do tipo Broadcast\n",
    "bc_media = sc.broadcast(medias)\n",
    "bc_desvio = sc.broadcast(desvios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para centralizar e aplicar escala aos dados. Cada valor será subtraído da média então dividido pelo desvio padrão\n",
    "def centerAndScale(inRow) :\n",
    "    global bc_media\n",
    "    global bc_desvio\n",
    "    \n",
    "    meanArray = bc_media.value\n",
    "    stdArray = bc_desvio.value\n",
    "\n",
    "    retArray = []\n",
    "    \n",
    "    for i in range(len(meanArray)):\n",
    "        retArray.append( (float(inRow[i]) - float(meanArray[i])) / float(stdArray[i]) )\n",
    "    return Vectors.dense(retArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrosRDD4 = carrosDF.rdd.map(centerAndScale)\n",
    "carrosRDD4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Dataframe\n",
    "carrosRDD5 = carrosRDD4.map( lambda f:Row(features = f))\n",
    "carrosDF = spSession.createDataFrame(carrosRDD5)\n",
    "carrosDF.select(\"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "kmeans = KMeans(k = 3, seed = 1)\n",
    "modelo = kmeans.fit(carrosDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões\n",
    "previsoes = modelo.transform(carrosDF)\n",
    "previsoes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstripData(instr) :\n",
    "    return (instr[\"prediction\"], instr[\"features\"][0], instr[\"features\"][1],\n",
    "            instr[\"features\"][2], instr[\"features\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrosRDD6 = previsoes.rdd.map(unstripData)\n",
    "predList = carrosRDD6.collect()\n",
    "predPd = pd.DataFrame(predList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico com o resultados dos clusters criados\n",
    "plt.cla()\n",
    "plt.scatter(predPd[3], predPd[4], c = predPd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
